{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f888e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "folder_path = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(folder_path, '..')))\n",
    "\n",
    "from csv_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58203cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_id</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>city</th>\n",
       "      <th>geonames_city_id</th>\n",
       "      <th>author_position</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/W100000002</td>\n",
       "      <td>1988</td>\n",
       "      <td>https://openalex.org/I4210095140</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Durham</td>\n",
       "      <td>4464368</td>\n",
       "      <td>first</td>\n",
       "      <td>https://openalex.org/A5012874907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/W100000002</td>\n",
       "      <td>1988</td>\n",
       "      <td>https://openalex.org/I4210095140</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Durham</td>\n",
       "      <td>4464368</td>\n",
       "      <td>last</td>\n",
       "      <td>https://openalex.org/A5006412880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/W1000000251</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://openalex.org/I1292966370</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>London</td>\n",
       "      <td>2643743</td>\n",
       "      <td>first</td>\n",
       "      <td>https://openalex.org/A5057387418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W1000000251</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://openalex.org/I1292966370</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>London</td>\n",
       "      <td>2643743</td>\n",
       "      <td>last</td>\n",
       "      <td>https://openalex.org/A5035275962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/W1000000589</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://openalex.org/I7877124</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2950159</td>\n",
       "      <td>first</td>\n",
       "      <td>https://openalex.org/A5091270897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://openalex.org/W1000000589</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://openalex.org/I7877124</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2950159</td>\n",
       "      <td>last</td>\n",
       "      <td>https://openalex.org/A5071995676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://openalex.org/W1000001125</td>\n",
       "      <td>2001</td>\n",
       "      <td>https://openalex.org/I231086526</td>\n",
       "      <td>Poland</td>\n",
       "      <td>PL</td>\n",
       "      <td>Siedlce</td>\n",
       "      <td>759412</td>\n",
       "      <td>first</td>\n",
       "      <td>https://openalex.org/A5060029945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://openalex.org/W1000001192</td>\n",
       "      <td>1988</td>\n",
       "      <td>https://openalex.org/I1328594524</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>4393217</td>\n",
       "      <td>first</td>\n",
       "      <td>https://openalex.org/A5072333347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://openalex.org/W1000001192</td>\n",
       "      <td>1988</td>\n",
       "      <td>https://openalex.org/I4210128618</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>4273837</td>\n",
       "      <td>first</td>\n",
       "      <td>https://openalex.org/A5072333347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://openalex.org/W1000001555</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://openalex.org/I2802849423</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Lubbock</td>\n",
       "      <td>5525577</td>\n",
       "      <td>first</td>\n",
       "      <td>https://openalex.org/A5050684082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://openalex.org/W1000001555</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://openalex.org/I2802849423</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Lubbock</td>\n",
       "      <td>5525577</td>\n",
       "      <td>last</td>\n",
       "      <td>https://openalex.org/A5050464501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://openalex.org/W1000002278</td>\n",
       "      <td>2015</td>\n",
       "      <td>https://openalex.org/I119868032</td>\n",
       "      <td>China</td>\n",
       "      <td>CN</td>\n",
       "      <td>Mingxing</td>\n",
       "      <td>1793691</td>\n",
       "      <td>first</td>\n",
       "      <td>https://openalex.org/A5088461704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://openalex.org/W1000002278</td>\n",
       "      <td>2015</td>\n",
       "      <td>https://openalex.org/I119868032</td>\n",
       "      <td>China</td>\n",
       "      <td>CN</td>\n",
       "      <td>Mingxing</td>\n",
       "      <td>1793691</td>\n",
       "      <td>middle</td>\n",
       "      <td>https://openalex.org/A5037177977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://openalex.org/W1000002278</td>\n",
       "      <td>2015</td>\n",
       "      <td>https://openalex.org/I119868032</td>\n",
       "      <td>China</td>\n",
       "      <td>CN</td>\n",
       "      <td>Mingxing</td>\n",
       "      <td>1793691</td>\n",
       "      <td>middle</td>\n",
       "      <td>https://openalex.org/A5022831628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://openalex.org/W1000002278</td>\n",
       "      <td>2015</td>\n",
       "      <td>https://openalex.org/I119868032</td>\n",
       "      <td>China</td>\n",
       "      <td>CN</td>\n",
       "      <td>Mingxing</td>\n",
       "      <td>1793691</td>\n",
       "      <td>middle</td>\n",
       "      <td>https://openalex.org/A5011787061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             work_id  publication_year  \\\n",
       "0    https://openalex.org/W100000002              1988   \n",
       "1    https://openalex.org/W100000002              1988   \n",
       "2   https://openalex.org/W1000000251              1990   \n",
       "3   https://openalex.org/W1000000251              1990   \n",
       "4   https://openalex.org/W1000000589              2010   \n",
       "5   https://openalex.org/W1000000589              2010   \n",
       "6   https://openalex.org/W1000001125              2001   \n",
       "7   https://openalex.org/W1000001192              1988   \n",
       "8   https://openalex.org/W1000001192              1988   \n",
       "9   https://openalex.org/W1000001555              2011   \n",
       "10  https://openalex.org/W1000001555              2011   \n",
       "11  https://openalex.org/W1000002278              2015   \n",
       "12  https://openalex.org/W1000002278              2015   \n",
       "13  https://openalex.org/W1000002278              2015   \n",
       "14  https://openalex.org/W1000002278              2015   \n",
       "\n",
       "                      institution_id         country country_code  \\\n",
       "0   https://openalex.org/I4210095140   United States           US   \n",
       "1   https://openalex.org/I4210095140   United States           US   \n",
       "2   https://openalex.org/I1292966370  United Kingdom           GB   \n",
       "3   https://openalex.org/I1292966370  United Kingdom           GB   \n",
       "4      https://openalex.org/I7877124         Germany           DE   \n",
       "5      https://openalex.org/I7877124         Germany           DE   \n",
       "6    https://openalex.org/I231086526          Poland           PL   \n",
       "7   https://openalex.org/I1328594524   United States           US   \n",
       "8   https://openalex.org/I4210128618   United States           US   \n",
       "9   https://openalex.org/I2802849423   United States           US   \n",
       "10  https://openalex.org/I2802849423   United States           US   \n",
       "11   https://openalex.org/I119868032           China           CN   \n",
       "12   https://openalex.org/I119868032           China           CN   \n",
       "13   https://openalex.org/I119868032           China           CN   \n",
       "14   https://openalex.org/I119868032           China           CN   \n",
       "\n",
       "           city  geonames_city_id author_position  \\\n",
       "0        Durham           4464368           first   \n",
       "1        Durham           4464368            last   \n",
       "2        London           2643743           first   \n",
       "3        London           2643743            last   \n",
       "4        Berlin           2950159           first   \n",
       "5        Berlin           2950159            last   \n",
       "6       Siedlce            759412           first   \n",
       "7   Kansas City           4393217           first   \n",
       "8   Kansas City           4273837           first   \n",
       "9       Lubbock           5525577           first   \n",
       "10      Lubbock           5525577            last   \n",
       "11     Mingxing           1793691           first   \n",
       "12     Mingxing           1793691          middle   \n",
       "13     Mingxing           1793691          middle   \n",
       "14     Mingxing           1793691          middle   \n",
       "\n",
       "                           author_id  \n",
       "0   https://openalex.org/A5012874907  \n",
       "1   https://openalex.org/A5006412880  \n",
       "2   https://openalex.org/A5057387418  \n",
       "3   https://openalex.org/A5035275962  \n",
       "4   https://openalex.org/A5091270897  \n",
       "5   https://openalex.org/A5071995676  \n",
       "6   https://openalex.org/A5060029945  \n",
       "7   https://openalex.org/A5072333347  \n",
       "8   https://openalex.org/A5072333347  \n",
       "9   https://openalex.org/A5050684082  \n",
       "10  https://openalex.org/A5050464501  \n",
       "11  https://openalex.org/A5088461704  \n",
       "12  https://openalex.org/A5037177977  \n",
       "13  https://openalex.org/A5022831628  \n",
       "14  https://openalex.org/A5011787061  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_first_n_rows(\"../data/q2/merged_openalex_works_data.csv\", nrows=15)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662b3ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 364045619\n"
     ]
    }
   ],
   "source": [
    "total_records = count_records_in_csv(\"../data/q2/merged_openalex_works_data.csv\")\n",
    "print(f\"Total records: {total_records}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908ec055",
   "metadata": {},
   "source": [
    " יוצר קובץ של שם כותב וכל השנים ומדינות הפרסום שלו"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd431e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating total number of lines in the file...\n",
      "Total number of chunks: 3641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/3641 [00:00<?, ?chunk/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process the chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|██████████| 3641/3641 [3:43:38<00:00,  3.69s/chunk]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all chunks. Creating final DataFrame...\n",
      "Saving the processed data to data/q2/processed_author_data.csv...\n",
      "Data saved successfully to data/q2/processed_author_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# נתיב לקובץ ה-CSV\n",
    "file_path = '../data/q2/merged_openalex_works_data.csv'\n",
    "\n",
    "# פונקציה לקריאה מהירה ב-Pandas על פי חתך בגודל 100,000 שורות\n",
    "def process_large_csv_and_merge(file_path, output_file):\n",
    "    chunk_size = 100000\n",
    "    author_data = defaultdict(list)  # מילון שמאכסן רשימות של זוגות (year, country)\n",
    "    \n",
    "    # קריאת הקובץ כדי לחשב את מספר החתיכים (chunks)\n",
    "    print(\"Calculating total number of lines in the file...\")\n",
    "    total_lines = sum(1 for _ in open(file_path))  # סופר את מספר השורות בקובץ\n",
    "    total_chunks = total_lines // chunk_size + (1 if total_lines % chunk_size > 0 else 0)\n",
    "    print(f\"Total number of chunks: {total_chunks}\")\n",
    "\n",
    "    # שימוש ב-tqdm להציג את התקדמות הקריאה\n",
    "    with tqdm(total=total_chunks, desc=\"Processing chunks\", unit=\"chunk\") as pbar:\n",
    "        # קריאת הקובץ בחתיכות ופילוט כל חתיך\n",
    "        print(\"Starting to process the chunks...\")\n",
    "        for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "            # עיבוד כל חתיך\n",
    "            chunk = chunk[['author_id', 'publication_year', 'country']]\n",
    "            \n",
    "            # עובר על כל שורה ומוסיף את השנה והמדינה לרשימה של אותו כותב\n",
    "            for _, row in chunk.iterrows():\n",
    "                author_id = row['author_id']\n",
    "                year_country_pair = (row['publication_year'], row['country'])\n",
    "                \n",
    "                # מוסיף את הזוג לרשימה של הכותב במילון\n",
    "                author_data[author_id].append(year_country_pair)\n",
    "            \n",
    "            # עדכון התקדמות עבור כל חתיכה\n",
    "            pbar.update(1)\n",
    "\n",
    "    # יצירת DataFrame ושמירת התוצאה\n",
    "    print(\"Finished processing all chunks. Creating final DataFrame...\")\n",
    "    author_data_list = [(author_id, year_country_pairs) for author_id, year_country_pairs in author_data.items()]\n",
    "    result_df = pd.DataFrame(author_data_list, columns=['author_id', 'year_country_pairs'])\n",
    "    \n",
    "    # שמירת התוצאה לקובץ\n",
    "    print(f\"Saving the processed data to {output_file}...\")\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved successfully to {output_file}\")\n",
    "\n",
    "# קריאה לפונקציה עם הנתיב לקובץ הפלט\n",
    "output_file = '../data/moving_between_countries/processed_author_data.csv'\n",
    "process_large_csv_and_merge(file_path, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e88503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>year_country_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/A5012874907</td>\n",
       "      <td>[(1988, 'United States'), (1988, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/A5006412880</td>\n",
       "      <td>[(1988, 'United States'), (1979, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/A5057387418</td>\n",
       "      <td>[(1990, 'United Kingdom'), (2010, 'Germany'), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/A5035275962</td>\n",
       "      <td>[(1990, 'United Kingdom'), (1982, 'United King...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/A5091270897</td>\n",
       "      <td>[(2010, 'Germany'), (1992, 'Germany'), (1997, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://openalex.org/A5071995676</td>\n",
       "      <td>[(2010, 'Germany'), (2014, 'Germany'), (2005, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://openalex.org/A5060029945</td>\n",
       "      <td>[(2001, 'Poland'), (2003, 'Poland'), (2012, 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://openalex.org/A5072333347</td>\n",
       "      <td>[(1988, 'United States'), (1988, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://openalex.org/A5050684082</td>\n",
       "      <td>[(2011, 'United States'), (2012, 'Netherlands'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://openalex.org/A5050464501</td>\n",
       "      <td>[(2011, 'United States'), (2012, 'Netherlands'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://openalex.org/A5088461704</td>\n",
       "      <td>[(2015, 'China'), (2014, 'China'), (2010, 'Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://openalex.org/A5037177977</td>\n",
       "      <td>[(2015, 'China'), (2016, 'China'), (2016, 'Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://openalex.org/A5022831628</td>\n",
       "      <td>[(2015, 'China'), (2014, 'China'), (2000, 'Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://openalex.org/A5011787061</td>\n",
       "      <td>[(2015, 'China'), (2014, 'China'), (2014, 'Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://openalex.org/A5017785808</td>\n",
       "      <td>[(2015, 'China'), (2011, 'United States'), (19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           author_id  \\\n",
       "0   https://openalex.org/A5012874907   \n",
       "1   https://openalex.org/A5006412880   \n",
       "2   https://openalex.org/A5057387418   \n",
       "3   https://openalex.org/A5035275962   \n",
       "4   https://openalex.org/A5091270897   \n",
       "5   https://openalex.org/A5071995676   \n",
       "6   https://openalex.org/A5060029945   \n",
       "7   https://openalex.org/A5072333347   \n",
       "8   https://openalex.org/A5050684082   \n",
       "9   https://openalex.org/A5050464501   \n",
       "10  https://openalex.org/A5088461704   \n",
       "11  https://openalex.org/A5037177977   \n",
       "12  https://openalex.org/A5022831628   \n",
       "13  https://openalex.org/A5011787061   \n",
       "14  https://openalex.org/A5017785808   \n",
       "\n",
       "                                   year_country_pairs  \n",
       "0   [(1988, 'United States'), (1988, 'United State...  \n",
       "1   [(1988, 'United States'), (1979, 'United State...  \n",
       "2   [(1990, 'United Kingdom'), (2010, 'Germany'), ...  \n",
       "3   [(1990, 'United Kingdom'), (1982, 'United King...  \n",
       "4   [(2010, 'Germany'), (1992, 'Germany'), (1997, ...  \n",
       "5   [(2010, 'Germany'), (2014, 'Germany'), (2005, ...  \n",
       "6   [(2001, 'Poland'), (2003, 'Poland'), (2012, 'P...  \n",
       "7   [(1988, 'United States'), (1988, 'United State...  \n",
       "8   [(2011, 'United States'), (2012, 'Netherlands'...  \n",
       "9   [(2011, 'United States'), (2012, 'Netherlands'...  \n",
       "10  [(2015, 'China'), (2014, 'China'), (2010, 'Chi...  \n",
       "11  [(2015, 'China'), (2016, 'China'), (2016, 'Chi...  \n",
       "12  [(2015, 'China'), (2014, 'China'), (2000, 'Chi...  \n",
       "13  [(2015, 'China'), (2014, 'China'), (2014, 'Chi...  \n",
       "14  [(2015, 'China'), (2011, 'United States'), (19...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_first_n_rows(\"../data/moving_between_countries/processed_author_data.csv\", nrows=15)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861812c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 32852780\n"
     ]
    }
   ],
   "source": [
    "total_records = count_records_in_csv(\"../data/moving_between_countries/processed_author_data.csv\")\n",
    "print(f\"Total records: {total_records}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90866dcb",
   "metadata": {},
   "source": [
    "יוצר קובץ שמכיל רק כותבים שהחליפו מדינה"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4382d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the process of filtering authors with country changes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing authors: 100%|██████████| 32852780/32852780 [49:23<00:00, 11086.28author/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the processed data to data/q2/authors_with_country_changes.csv...\n",
      "Data has been saved successfully to data/q2/authors_with_country_changes.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# נתיב לקובץ הקלט\n",
    "input_file = '../data/moving_between_countries/processed_author_data.csv'\n",
    "# נתיב לקובץ הפלט\n",
    "output_file = '../data/moving_between_countries/authors_with_country_changes.csv'\n",
    "\n",
    "# קריאה לקובץ הקלט\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# פונקציה לבדוק אם כותב החליף מדינה\n",
    "def has_changed_country(year_country_pairs):\n",
    "    countries = set([country for _, country in year_country_pairs])\n",
    "    return len(countries) > 1\n",
    "\n",
    "# יצירת קובץ חדש שיכיל רק כותבים שהחליפו מדינה\n",
    "filtered_authors = []\n",
    "\n",
    "# הדפסת הודעה על תחילת הקריאה והעיבוד\n",
    "print(\"Starting the process of filtering authors with country changes...\")\n",
    "\n",
    "# עובר על כל כותב ומסנן את כותבים שהחליפו מדינה\n",
    "with tqdm(total=len(df), desc=\"Processing authors\", unit=\"author\") as pbar:\n",
    "    for _, row in df.iterrows():\n",
    "        author_id = row['author_id']\n",
    "        year_country_pairs = eval(row['year_country_pairs'])  # משנה את המייצג של הרשימה לצורת רשימה אמיתית\n",
    "        \n",
    "        # אם הכותב החליף מדינה, נוסיף אותו לרשימה\n",
    "        if has_changed_country(year_country_pairs):\n",
    "            # ממיין את רשימת הזוגות לפי שנה\n",
    "            sorted_pairs = sorted(year_country_pairs, key=lambda x: x[0])  # מיון לפי השנה\n",
    "            filtered_authors.append([author_id, sorted_pairs])\n",
    "        \n",
    "        # עדכון התקדמות עבור כל כותב\n",
    "        pbar.update(1)\n",
    "\n",
    "# המרת הרשימה ל-DataFrame\n",
    "filtered_df = pd.DataFrame(filtered_authors, columns=['author_id', 'year_country_pairs'])\n",
    "\n",
    "# שמירה לקובץ חדש\n",
    "print(f\"Saving the processed data to {output_file}...\")\n",
    "filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data has been saved successfully to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82c99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 5644034\n"
     ]
    }
   ],
   "source": [
    "total_records = count_records_in_csv(\"../data/moving_between_countries/authors_with_country_changes.csv\")\n",
    "print(f\"Total records: {total_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395657ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>year_country_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/A5012874907</td>\n",
       "      <td>[(1976, 'United States'), (1977, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/A5057387418</td>\n",
       "      <td>[(1990, 'United Kingdom'), (1990, 'United King...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/A5035275962</td>\n",
       "      <td>[(1971, 'Australia'), (1976, 'Sweden'), (1976,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/A5091270897</td>\n",
       "      <td>[(1984, 'Germany'), (1992, 'Germany'), (1994, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/A5071995676</td>\n",
       "      <td>[(1999, 'Germany'), (1999, 'Germany'), (2001, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://openalex.org/A5050684082</td>\n",
       "      <td>[(1987, 'Netherlands'), (1987, 'Netherlands'),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://openalex.org/A5050464501</td>\n",
       "      <td>[(2008, 'Netherlands'), (2010, 'Netherlands'),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://openalex.org/A5022831628</td>\n",
       "      <td>[(1997, 'United Kingdom'), (1997, 'China'), (2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://openalex.org/A5011787061</td>\n",
       "      <td>[(1994, 'United States'), (1997, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://openalex.org/A5017785808</td>\n",
       "      <td>[(1988, 'United States'), (1993, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://openalex.org/A5049620625</td>\n",
       "      <td>[(2006, 'China'), (2007, 'China'), (2008, 'Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://openalex.org/A5038537133</td>\n",
       "      <td>[(2002, 'United States'), (2003, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://openalex.org/A5073336210</td>\n",
       "      <td>[(1994, 'France'), (1994, 'France'), (1994, 'F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://openalex.org/A5075806177</td>\n",
       "      <td>[(1997, 'United States'), (1997, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://openalex.org/A5087270154</td>\n",
       "      <td>[(2005, 'Germany'), (2005, 'Germany'), (2006, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           author_id  \\\n",
       "0   https://openalex.org/A5012874907   \n",
       "1   https://openalex.org/A5057387418   \n",
       "2   https://openalex.org/A5035275962   \n",
       "3   https://openalex.org/A5091270897   \n",
       "4   https://openalex.org/A5071995676   \n",
       "5   https://openalex.org/A5050684082   \n",
       "6   https://openalex.org/A5050464501   \n",
       "7   https://openalex.org/A5022831628   \n",
       "8   https://openalex.org/A5011787061   \n",
       "9   https://openalex.org/A5017785808   \n",
       "10  https://openalex.org/A5049620625   \n",
       "11  https://openalex.org/A5038537133   \n",
       "12  https://openalex.org/A5073336210   \n",
       "13  https://openalex.org/A5075806177   \n",
       "14  https://openalex.org/A5087270154   \n",
       "\n",
       "                                   year_country_pairs  \n",
       "0   [(1976, 'United States'), (1977, 'United State...  \n",
       "1   [(1990, 'United Kingdom'), (1990, 'United King...  \n",
       "2   [(1971, 'Australia'), (1976, 'Sweden'), (1976,...  \n",
       "3   [(1984, 'Germany'), (1992, 'Germany'), (1994, ...  \n",
       "4   [(1999, 'Germany'), (1999, 'Germany'), (2001, ...  \n",
       "5   [(1987, 'Netherlands'), (1987, 'Netherlands'),...  \n",
       "6   [(2008, 'Netherlands'), (2010, 'Netherlands'),...  \n",
       "7   [(1997, 'United Kingdom'), (1997, 'China'), (2...  \n",
       "8   [(1994, 'United States'), (1997, 'United State...  \n",
       "9   [(1988, 'United States'), (1993, 'United State...  \n",
       "10  [(2006, 'China'), (2007, 'China'), (2008, 'Chi...  \n",
       "11  [(2002, 'United States'), (2003, 'United State...  \n",
       "12  [(1994, 'France'), (1994, 'France'), (1994, 'F...  \n",
       "13  [(1997, 'United States'), (1997, 'United State...  \n",
       "14  [(2005, 'Germany'), (2005, 'Germany'), (2006, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_first_n_rows(\"../data/moving_between_countries/authors_with_country_changes.csv\", nrows=15)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b855e07",
   "metadata": {},
   "source": [
    "## יצירת קובץ שמגדיר את כל המעברים בין מדינות"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e988e1e7",
   "metadata": {},
   "source": [
    "\n",
    "מעבר: שינוי מדינה בין שני פרסומים עוקבים של אותו חוקר, גם אם באותה שנה.\n",
    "\n",
    "שנת המעבר: שנת הפרסום במדינת היעד.\n",
    "\n",
    "עזיבה קבועה: A→B בשנה t, ואין פרסום במדינת A בחלון t+1 עד t+X.\n",
    "\n",
    "עזיבה זמנית: A→B בשנה t, ויש פרסום במדינת A בחלון t+1 עד t+X.\n",
    "\n",
    "הגעה קבועה: A→B בשנה t, ואין פרסום במדינה אחרת כלשהי בחלון t+1 עד t+X.\n",
    "\n",
    "הגעה זמנית: A→B בשנה t, ויש פרסום במדינה אחרת כלשהי בחלון t+1 עד t+X.\n",
    "\n",
    "פרסומים: נספרת כל רשומת (שנה, מדינה) בנתונים שלך, כלומר מספר עבודות, לא מספר חוקרים ייחודיים.\n",
    "\n",
    "ברירת מחדל X=3 שנים, ניתן לשינוי."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331bafb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 5644034rows [30:54, 3044.12rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Parsed rows: 5644034, skipped rows: 0, unique (year,country) cells: 21066\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def parse_year_country_pairs(s: str) -> List[Tuple[int, str]]:\n",
    "    \"\"\"\n",
    "    Parse a string like \"[(1976, 'United States'), (1977, 'United States')]\" to [(1976,'United States'), ...]\n",
    "    Returns cleaned list with int years and stripped country strings.\n",
    "    \"\"\"\n",
    "    if s is None or s == \"\" or pd.isna(s):\n",
    "        return []\n",
    "    try:\n",
    "        pairs = ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        return []\n",
    "    out = []\n",
    "    for item in pairs:\n",
    "        if not isinstance(item, (list, tuple)) or len(item) != 2:\n",
    "            continue\n",
    "        y, c = item\n",
    "        if y is None or c is None:\n",
    "            continue\n",
    "        try:\n",
    "            y = int(y)\n",
    "        except Exception:\n",
    "            continue\n",
    "        out.append((y, str(c).strip()))\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_country_year_metrics_streaming(\n",
    "    input_csv_path: str,\n",
    "    output_csv_path: str,\n",
    "    x_perm_years: int = 3,\n",
    "    chunksize: int = 50_000,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Streaming computation of yearly country metrics from a very large CSV.\n",
    "\n",
    "    Input CSV must contain columns: author_id, year_country_pairs.\n",
    "\n",
    "    Output CSV columns per (year, country):\n",
    "      - left_permanent\n",
    "      - left_temporary\n",
    "      - arrived_permanent\n",
    "      - arrived_temporary\n",
    "      - arrived_total\n",
    "      - publications\n",
    "    \"\"\"\n",
    "    left_perm = defaultdict(int)        # (year, country_from)\n",
    "    left_temp = defaultdict(int)        # (year, country_from)\n",
    "    arr_perm = defaultdict(int)         # (year, country_to)\n",
    "    arr_temp = defaultdict(int)         # (year, country_to)\n",
    "    publications = defaultdict(int)     # (year, country)\n",
    "\n",
    "    parsed_rows = 0\n",
    "    skipped_rows = 0\n",
    "\n",
    "    reader = pd.read_csv(\n",
    "        input_csv_path,\n",
    "        usecols=[\"author_id\", \"year_country_pairs\"],\n",
    "        dtype={\"author_id\": \"string\", \"year_country_pairs\": \"string\"},\n",
    "        chunksize=chunksize,\n",
    "        low_memory=True,\n",
    "    )\n",
    "\n",
    "    # progress bar without a known total\n",
    "    pbar = tqdm(unit=\"rows\", desc=\"Processing\", dynamic_ncols=True, smoothing=0.1)\n",
    "\n",
    "    for chunk in reader:\n",
    "        for _, row in chunk.iterrows():\n",
    "            pairs = parse_year_country_pairs(row[\"year_country_pairs\"])\n",
    "            if not pairs:\n",
    "                skipped_rows += 1\n",
    "                continue\n",
    "\n",
    "            # publications: count every (year, country)\n",
    "            for y, c in pairs:\n",
    "                publications[(y, c)] += 1\n",
    "\n",
    "            # stable sort by year, preserve original order within same year\n",
    "            pairs_with_idx = list(enumerate(pairs))\n",
    "            pairs_sorted = [p for _, p in sorted(pairs_with_idx, key=lambda x: (x[1][0], x[0]))]\n",
    "\n",
    "            # deduplicate same (year, country) within author\n",
    "            seen_yc = set()\n",
    "            seq = []\n",
    "            for y, c in pairs_sorted:\n",
    "                key = (y, c)\n",
    "                if key in seen_yc:\n",
    "                    continue\n",
    "                seen_yc.add(key)\n",
    "                seq.append((y, c))\n",
    "\n",
    "            n = len(seq)\n",
    "            if n >= 2:\n",
    "                for i in range(n - 1):\n",
    "                    y_from, c_from = seq[i]\n",
    "                    y_to, c_to = seq[i + 1]\n",
    "                    if c_from == c_to:\n",
    "                        continue\n",
    "                    t = y_to  # transition year is target year\n",
    "\n",
    "                    # leave classification for origin country\n",
    "                    returned_to_origin_within_window = False\n",
    "                    for j in range(i + 2, n):\n",
    "                        y_future, c_future = seq[j]\n",
    "                        if y_future > t + x_perm_years:\n",
    "                            break\n",
    "                        if c_future == c_from and y_future >= t + 1:\n",
    "                            returned_to_origin_within_window = True\n",
    "                            break\n",
    "                    if returned_to_origin_within_window:\n",
    "                        left_temp[(t, c_from)] += 1\n",
    "                    else:\n",
    "                        left_perm[(t, c_from)] += 1\n",
    "\n",
    "                    # arrival classification for destination country\n",
    "                    left_destination_within_window = False\n",
    "                    for j in range(i + 2, n):\n",
    "                        y_future, c_future = seq[j]\n",
    "                        if y_future > t + x_perm_years:\n",
    "                            break\n",
    "                        if c_future != c_to and y_future >= t + 1:\n",
    "                            left_destination_within_window = True\n",
    "                            break\n",
    "                    if left_destination_within_window:\n",
    "                        arr_temp[(t, c_to)] += 1\n",
    "                    else:\n",
    "                        arr_perm[(t, c_to)] += 1\n",
    "\n",
    "            parsed_rows += 1\n",
    "\n",
    "        pbar.update(len(chunk))\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # build output\n",
    "    keys = set()\n",
    "    keys |= set(left_perm.keys())\n",
    "    keys |= set(left_temp.keys())\n",
    "    keys |= set(arr_perm.keys())\n",
    "    keys |= set(arr_temp.keys())\n",
    "    keys |= set(publications.keys())\n",
    "\n",
    "    records = []\n",
    "    for (y, c) in keys:\n",
    "        ap = arr_perm.get((y, c), 0)\n",
    "        at = arr_temp.get((y, c), 0)\n",
    "        records.append({\n",
    "            \"year\": y,\n",
    "            \"country\": c,\n",
    "            \"left_permanent\": left_perm.get((y, c), 0),\n",
    "            \"left_temporary\": left_temp.get((y, c), 0),\n",
    "            \"arrived_permanent\": ap,\n",
    "            \"arrived_temporary\": at,\n",
    "            \"arrived_total\": ap + at,\n",
    "            \"publications\": publications.get((y, c), 0),\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(records).sort_values([\"year\", \"country\"]).reset_index(drop=True)\n",
    "    out.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Done. Parsed rows: {parsed_rows}, skipped rows: {skipped_rows}, unique (year,country) cells: {len(keys)}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# Example:\n",
    "output_df = compute_country_year_metrics_streaming(\n",
    "    input_csv_path=\"../data/moving_between_countries/authors_with_country_changes.csv\",\n",
    "    output_csv_path=\"../data/moving_between_countries/country_year_metrics.csv\",\n",
    "    x_perm_years=3,\n",
    "    chunksize=50_000\n",
    ")\n",
    "# print(output_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5538b454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>left_permanent</th>\n",
       "      <th>left_temporary</th>\n",
       "      <th>arrived_permanent</th>\n",
       "      <th>arrived_temporary</th>\n",
       "      <th>arrived_total</th>\n",
       "      <th>publications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1862</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1862</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1862</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1862</td>\n",
       "      <td>Chile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1862</td>\n",
       "      <td>Czechia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year   country  left_permanent  left_temporary  arrived_permanent  \\\n",
       "0       4     China               0               0                  0   \n",
       "1       4    France               0               0                  0   \n",
       "2      27    France               0               0                  0   \n",
       "3      29    France               0               0                  0   \n",
       "4     208   Hungary               0               0                  1   \n",
       "..    ...       ...             ...             ...                ...   \n",
       "995  1862    Brazil               0               0                  2   \n",
       "996  1862  Cameroon               0               0                  1   \n",
       "997  1862    Canada               0               0                  2   \n",
       "998  1862     Chile               0               0                  0   \n",
       "999  1862   Czechia               0               0                  0   \n",
       "\n",
       "     arrived_temporary  arrived_total  publications  \n",
       "0                    0              0             4  \n",
       "1                    0              0             1  \n",
       "2                    0              0             4  \n",
       "3                    0              0             3  \n",
       "4                    0              1             1  \n",
       "..                 ...            ...           ...  \n",
       "995                  0              2             7  \n",
       "996                  0              1             1  \n",
       "997                  1              3            18  \n",
       "998                  0              0             1  \n",
       "999                  0              0             1  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_first_n_rows(\"../data/moving_between_countries/country_year_metrics.csv\", nrows=1000)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63fb22f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 21066\n"
     ]
    }
   ],
   "source": [
    "total_records = count_records_in_csv(\"../data/moving_between_countries/country_year_metrics.csv\")\n",
    "print(f\"Total records: {total_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730f4ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>left_permanent</th>\n",
       "      <th>left_temporary</th>\n",
       "      <th>arrived_permanent</th>\n",
       "      <th>arrived_temporary</th>\n",
       "      <th>arrived_total</th>\n",
       "      <th>publications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1802</td>\n",
       "      <td>Israel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1807</td>\n",
       "      <td>Israel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>1874</td>\n",
       "      <td>Israel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>1876</td>\n",
       "      <td>Israel</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1879</td>\n",
       "      <td>Israel</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20084</th>\n",
       "      <td>2020</td>\n",
       "      <td>Israel</td>\n",
       "      <td>3465</td>\n",
       "      <td>3941</td>\n",
       "      <td>2310</td>\n",
       "      <td>5165</td>\n",
       "      <td>7475</td>\n",
       "      <td>72401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20308</th>\n",
       "      <td>2021</td>\n",
       "      <td>Israel</td>\n",
       "      <td>4179</td>\n",
       "      <td>3239</td>\n",
       "      <td>2974</td>\n",
       "      <td>4780</td>\n",
       "      <td>7754</td>\n",
       "      <td>80997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20533</th>\n",
       "      <td>2022</td>\n",
       "      <td>Israel</td>\n",
       "      <td>4354</td>\n",
       "      <td>2375</td>\n",
       "      <td>3003</td>\n",
       "      <td>3427</td>\n",
       "      <td>6430</td>\n",
       "      <td>69284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20759</th>\n",
       "      <td>2023</td>\n",
       "      <td>Israel</td>\n",
       "      <td>6341</td>\n",
       "      <td>25</td>\n",
       "      <td>6187</td>\n",
       "      <td>139</td>\n",
       "      <td>6326</td>\n",
       "      <td>56166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20957</th>\n",
       "      <td>2024</td>\n",
       "      <td>Israel</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year country  left_permanent  left_temporary  arrived_permanent  \\\n",
       "160    1802  Israel               0               0                  0   \n",
       "210    1807  Israel               0               0                  0   \n",
       "1394   1874  Israel               0               0                  0   \n",
       "1473   1876  Israel               1               0                  0   \n",
       "1601   1879  Israel               1               0                  0   \n",
       "...     ...     ...             ...             ...                ...   \n",
       "20084  2020  Israel            3465            3941               2310   \n",
       "20308  2021  Israel            4179            3239               2974   \n",
       "20533  2022  Israel            4354            2375               3003   \n",
       "20759  2023  Israel            6341              25               6187   \n",
       "20957  2024  Israel              77               0                 35   \n",
       "\n",
       "       arrived_temporary  arrived_total  publications  \n",
       "160                    0              0             1  \n",
       "210                    0              0             1  \n",
       "1394                   0              0             1  \n",
       "1473                   0              0             1  \n",
       "1601                   0              0             0  \n",
       "...                  ...            ...           ...  \n",
       "20084               5165           7475         72401  \n",
       "20308               4780           7754         80997  \n",
       "20533               3427           6430         69284  \n",
       "20759                139           6326         56166  \n",
       "20957                  0             35           130  \n",
       "\n",
       "[121 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# קריאת הקובץ המלא\n",
    "df = pd.read_csv(\"../data/moving_between_countries/country_year_metrics.csv\")\n",
    "\n",
    "# סינון הרשומות של ישראל\n",
    "df_israel = df[df['country'] == 'Israel']\n",
    "\n",
    "# הצגת התוצאה\n",
    "df_israel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050160a7",
   "metadata": {},
   "source": [
    "יוצר קובץ של כל הכותבים שעברו מדינה, ואחת המדינות היא ישראל"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2099ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to data/q2/authors_country_changes_in_israel.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = '../data/moving_between_countries/authors_with_country_changes.csv'\n",
    "output_file = '../data/moving_between_countries/authors_country_changes_in_israel.csv'\n",
    "\n",
    "# Read the input CSV file\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Function to check if the author has been in Israel\n",
    "def was_in_israel(year_country_pairs):\n",
    "    # Check if any of the (year, country) pairs contains 'Israel'\n",
    "    return any(country == 'Israel' for _, country in year_country_pairs)\n",
    "\n",
    "# Create a new list to hold authors who have been in Israel\n",
    "filtered_authors = []\n",
    "\n",
    "# Iterate over each author and filter those who have been in Israel\n",
    "for _, row in df.iterrows():\n",
    "    author_id = row['author_id']\n",
    "    year_country_pairs = eval(row['year_country_pairs'])  # Convert string representation of list to actual list\n",
    "    \n",
    "    # If the author has been to Israel, add them to the filtered list\n",
    "    if was_in_israel(year_country_pairs):\n",
    "        filtered_authors.append([author_id, year_country_pairs])\n",
    "\n",
    "# Convert the list of filtered authors to a DataFrame\n",
    "filtered_df = pd.DataFrame(filtered_authors, columns=['author_id', 'year_country_pairs'])\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data has been saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0bb3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 109148\n"
     ]
    }
   ],
   "source": [
    "total_records = count_records_in_csv(\"../data/moving_between_countries/authors_country_changes_in_israel.csv\")\n",
    "print(f\"Total records: {total_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a924264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>year_country_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/A5060843284</td>\n",
       "      <td>[(1946, 'China'), (1956, 'United States'), (19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/A5042966626</td>\n",
       "      <td>[(1965, 'United States'), (1965, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/A5081258957</td>\n",
       "      <td>[(1953, 'United States'), (1954, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/A5058738251</td>\n",
       "      <td>[(1967, 'United States'), (1969, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/A5085070114</td>\n",
       "      <td>[(1982, 'South Africa'), (1982, 'South Africa'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://openalex.org/A5055529501</td>\n",
       "      <td>[(1989, 'Israel'), (1989, 'Israel'), (1993, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://openalex.org/A5063861158</td>\n",
       "      <td>[(1968, 'United States'), (1969, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://openalex.org/A5020398241</td>\n",
       "      <td>[(1987, 'United States'), (1987, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://openalex.org/A5026764667</td>\n",
       "      <td>[(1971, 'United States'), (1975, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://openalex.org/A5063463701</td>\n",
       "      <td>[(1995, 'Germany'), (1996, 'Germany'), (1997, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://openalex.org/A5087618628</td>\n",
       "      <td>[(1984, 'Germany'), (1984, 'Germany'), (1984, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://openalex.org/A5054114735</td>\n",
       "      <td>[(1973, 'Germany'), (1980, 'Germany'), (1981, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://openalex.org/A5006338014</td>\n",
       "      <td>[(1946, 'United Kingdom'), (1976, 'United King...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://openalex.org/A5030459373</td>\n",
       "      <td>[(1991, 'China'), (1997, 'China'), (2000, 'Uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://openalex.org/A5080143961</td>\n",
       "      <td>[(1994, 'United Kingdom'), (1996, 'China'), (2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://openalex.org/A5084282500</td>\n",
       "      <td>[(1982, 'Italy'), (1984, 'Italy'), (1984, 'Ita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://openalex.org/A5064247559</td>\n",
       "      <td>[(1987, 'Germany'), (1987, 'Germany'), (1989, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://openalex.org/A5050526454</td>\n",
       "      <td>[(1959, 'Japan'), (1965, 'United States'), (19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://openalex.org/A5004623672</td>\n",
       "      <td>[(1999, 'China'), (1999, 'China'), (2001, 'Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://openalex.org/A5018011627</td>\n",
       "      <td>[(2006, 'China'), (2012, 'Israel'), (2012, 'Is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://openalex.org/A5042762792</td>\n",
       "      <td>[(1997, 'Israel'), (1997, 'India'), (1997, 'Is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://openalex.org/A5085115963</td>\n",
       "      <td>[(1982, 'United States'), (1982, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://openalex.org/A5070752173</td>\n",
       "      <td>[(1962, 'United States'), (1964, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://openalex.org/A5067137772</td>\n",
       "      <td>[(2000, 'Canada'), (2003, 'Canada'), (2004, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://openalex.org/A5023016326</td>\n",
       "      <td>[(1978, 'United States'), (1979, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://openalex.org/A5061172285</td>\n",
       "      <td>[(1997, 'Israel'), (1998, 'Israel'), (1998, 'U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://openalex.org/A5029129951</td>\n",
       "      <td>[(1968, 'United States'), (1968, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://openalex.org/A5076029384</td>\n",
       "      <td>[(1978, 'United States'), (1979, 'United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://openalex.org/A5003483997</td>\n",
       "      <td>[(1935, 'Canada'), (1963, 'United States'), (1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://openalex.org/A5042246248</td>\n",
       "      <td>[(1984, 'Japan'), (2002, 'Japan'), (2002, 'Jap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           author_id  \\\n",
       "0   https://openalex.org/A5060843284   \n",
       "1   https://openalex.org/A5042966626   \n",
       "2   https://openalex.org/A5081258957   \n",
       "3   https://openalex.org/A5058738251   \n",
       "4   https://openalex.org/A5085070114   \n",
       "5   https://openalex.org/A5055529501   \n",
       "6   https://openalex.org/A5063861158   \n",
       "7   https://openalex.org/A5020398241   \n",
       "8   https://openalex.org/A5026764667   \n",
       "9   https://openalex.org/A5063463701   \n",
       "10  https://openalex.org/A5087618628   \n",
       "11  https://openalex.org/A5054114735   \n",
       "12  https://openalex.org/A5006338014   \n",
       "13  https://openalex.org/A5030459373   \n",
       "14  https://openalex.org/A5080143961   \n",
       "15  https://openalex.org/A5084282500   \n",
       "16  https://openalex.org/A5064247559   \n",
       "17  https://openalex.org/A5050526454   \n",
       "18  https://openalex.org/A5004623672   \n",
       "19  https://openalex.org/A5018011627   \n",
       "20  https://openalex.org/A5042762792   \n",
       "21  https://openalex.org/A5085115963   \n",
       "22  https://openalex.org/A5070752173   \n",
       "23  https://openalex.org/A5067137772   \n",
       "24  https://openalex.org/A5023016326   \n",
       "25  https://openalex.org/A5061172285   \n",
       "26  https://openalex.org/A5029129951   \n",
       "27  https://openalex.org/A5076029384   \n",
       "28  https://openalex.org/A5003483997   \n",
       "29  https://openalex.org/A5042246248   \n",
       "\n",
       "                                   year_country_pairs  \n",
       "0   [(1946, 'China'), (1956, 'United States'), (19...  \n",
       "1   [(1965, 'United States'), (1965, 'United State...  \n",
       "2   [(1953, 'United States'), (1954, 'United State...  \n",
       "3   [(1967, 'United States'), (1969, 'United State...  \n",
       "4   [(1982, 'South Africa'), (1982, 'South Africa'...  \n",
       "5   [(1989, 'Israel'), (1989, 'Israel'), (1993, 'I...  \n",
       "6   [(1968, 'United States'), (1969, 'United State...  \n",
       "7   [(1987, 'United States'), (1987, 'United State...  \n",
       "8   [(1971, 'United States'), (1975, 'United State...  \n",
       "9   [(1995, 'Germany'), (1996, 'Germany'), (1997, ...  \n",
       "10  [(1984, 'Germany'), (1984, 'Germany'), (1984, ...  \n",
       "11  [(1973, 'Germany'), (1980, 'Germany'), (1981, ...  \n",
       "12  [(1946, 'United Kingdom'), (1976, 'United King...  \n",
       "13  [(1991, 'China'), (1997, 'China'), (2000, 'Uni...  \n",
       "14  [(1994, 'United Kingdom'), (1996, 'China'), (2...  \n",
       "15  [(1982, 'Italy'), (1984, 'Italy'), (1984, 'Ita...  \n",
       "16  [(1987, 'Germany'), (1987, 'Germany'), (1989, ...  \n",
       "17  [(1959, 'Japan'), (1965, 'United States'), (19...  \n",
       "18  [(1999, 'China'), (1999, 'China'), (2001, 'Chi...  \n",
       "19  [(2006, 'China'), (2012, 'Israel'), (2012, 'Is...  \n",
       "20  [(1997, 'Israel'), (1997, 'India'), (1997, 'Is...  \n",
       "21  [(1982, 'United States'), (1982, 'United State...  \n",
       "22  [(1962, 'United States'), (1964, 'United State...  \n",
       "23  [(2000, 'Canada'), (2003, 'Canada'), (2004, 'I...  \n",
       "24  [(1978, 'United States'), (1979, 'United State...  \n",
       "25  [(1997, 'Israel'), (1998, 'Israel'), (1998, 'U...  \n",
       "26  [(1968, 'United States'), (1968, 'United State...  \n",
       "27  [(1978, 'United States'), (1979, 'United State...  \n",
       "28  [(1935, 'Canada'), (1963, 'United States'), (1...  \n",
       "29  [(1984, 'Japan'), (2002, 'Japan'), (2002, 'Jap...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_first_n_rows(\"../data/moving_between_countries/authors_country_changes_in_israel.csv\", nrows=30)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db85e0",
   "metadata": {},
   "source": [
    "#  מעברים מישראל ולישראל לפי שנה\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007c9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = '../data/moving_between_countries/country_year_metrics.csv'\n",
    "output_file = '../data/moving_between_countries/transitions_to_from_israel.csv'\n",
    "\n",
    "# קריאת הקובץ המלא\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# סינון הרשומות של ישראל\n",
    "df_israel = df[df['country'] == 'Israel']\n",
    "\n",
    "# הצגת התוצאה\n",
    "df_israel.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d95a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>left_permanent</th>\n",
       "      <th>left_temporary</th>\n",
       "      <th>arrived_permanent</th>\n",
       "      <th>arrived_temporary</th>\n",
       "      <th>arrived_total</th>\n",
       "      <th>publications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1802</td>\n",
       "      <td>Israel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1807</td>\n",
       "      <td>Israel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>1874</td>\n",
       "      <td>Israel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>1876</td>\n",
       "      <td>Israel</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1879</td>\n",
       "      <td>Israel</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20084</th>\n",
       "      <td>2020</td>\n",
       "      <td>Israel</td>\n",
       "      <td>3465</td>\n",
       "      <td>3941</td>\n",
       "      <td>2310</td>\n",
       "      <td>5165</td>\n",
       "      <td>7475</td>\n",
       "      <td>72401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20308</th>\n",
       "      <td>2021</td>\n",
       "      <td>Israel</td>\n",
       "      <td>4179</td>\n",
       "      <td>3239</td>\n",
       "      <td>2974</td>\n",
       "      <td>4780</td>\n",
       "      <td>7754</td>\n",
       "      <td>80997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20533</th>\n",
       "      <td>2022</td>\n",
       "      <td>Israel</td>\n",
       "      <td>4354</td>\n",
       "      <td>2375</td>\n",
       "      <td>3003</td>\n",
       "      <td>3427</td>\n",
       "      <td>6430</td>\n",
       "      <td>69284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20759</th>\n",
       "      <td>2023</td>\n",
       "      <td>Israel</td>\n",
       "      <td>6341</td>\n",
       "      <td>25</td>\n",
       "      <td>6187</td>\n",
       "      <td>139</td>\n",
       "      <td>6326</td>\n",
       "      <td>56166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20957</th>\n",
       "      <td>2024</td>\n",
       "      <td>Israel</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year country  left_permanent  left_temporary  arrived_permanent  \\\n",
       "160    1802  Israel               0               0                  0   \n",
       "210    1807  Israel               0               0                  0   \n",
       "1394   1874  Israel               0               0                  0   \n",
       "1473   1876  Israel               1               0                  0   \n",
       "1601   1879  Israel               1               0                  0   \n",
       "...     ...     ...             ...             ...                ...   \n",
       "20084  2020  Israel            3465            3941               2310   \n",
       "20308  2021  Israel            4179            3239               2974   \n",
       "20533  2022  Israel            4354            2375               3003   \n",
       "20759  2023  Israel            6341              25               6187   \n",
       "20957  2024  Israel              77               0                 35   \n",
       "\n",
       "       arrived_temporary  arrived_total  publications  \n",
       "160                    0              0             1  \n",
       "210                    0              0             1  \n",
       "1394                   0              0             1  \n",
       "1473                   0              0             1  \n",
       "1601                   0              0             0  \n",
       "...                  ...            ...           ...  \n",
       "20084               5165           7475         72401  \n",
       "20308               4780           7754         80997  \n",
       "20533               3427           6430         69284  \n",
       "20759                139           6326         56166  \n",
       "20957                  0             35           130  \n",
       "\n",
       "[121 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_israel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffe9969",
   "metadata": {},
   "source": [
    "## יצירת קובץ קלט לתרשים מסוג Sankey "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d31118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 109148rows [02:04, 873.52rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Parsed rows: 109148, skipped rows: 0, output rows: 8325\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def parse_year_country_pairs(s: str) -> List[Tuple[int, str]]:\n",
    "    if s is None or s == \"\" or pd.isna(s):\n",
    "        return []\n",
    "    try:\n",
    "        pairs = ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        return []\n",
    "    out = []\n",
    "    for item in pairs:\n",
    "        if not isinstance(item, (list, tuple)) or len(item) != 2:\n",
    "            continue\n",
    "        y, c = item\n",
    "        if y is None or c is None:\n",
    "            continue\n",
    "        try:\n",
    "            y = int(y)\n",
    "        except Exception:\n",
    "            continue\n",
    "        out.append((y, str(c).strip()))\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_sankey_metrics(\n",
    "    input_csv_path: str,\n",
    "    output_csv_path: str,\n",
    "    x_perm_years: int = 3,\n",
    "    chunksize: int = 50_000,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute source-target metrics for Sankey diagram, filtered for Israel.\n",
    "    \"\"\"\n",
    "    left_perm = defaultdict(int)\n",
    "    left_temp = defaultdict(int)\n",
    "    arr_perm = defaultdict(int)\n",
    "    arr_temp = defaultdict(int)\n",
    "\n",
    "    parsed_rows = 0\n",
    "    skipped_rows = 0\n",
    "\n",
    "    reader = pd.read_csv(\n",
    "        input_csv_path,\n",
    "        usecols=[\"author_id\", \"year_country_pairs\"],\n",
    "        dtype={\"author_id\": \"string\", \"year_country_pairs\": \"string\"},\n",
    "        chunksize=chunksize,\n",
    "        low_memory=True,\n",
    "    )\n",
    "\n",
    "    pbar = tqdm(unit=\"rows\", desc=\"Processing\", dynamic_ncols=True, smoothing=0.1)\n",
    "\n",
    "    for chunk in reader:\n",
    "        for _, row in chunk.iterrows():\n",
    "            pairs = parse_year_country_pairs(row[\"year_country_pairs\"])\n",
    "            if not pairs or len(pairs) < 2:\n",
    "                skipped_rows += 1\n",
    "                continue\n",
    "\n",
    "            # stable sort by year\n",
    "            pairs_with_idx = list(enumerate(pairs))\n",
    "            pairs_sorted = [p for _, p in sorted(pairs_with_idx, key=lambda x: (x[1][0], x[0]))]\n",
    "\n",
    "            # deduplicate\n",
    "            seen_yc = set()\n",
    "            seq = []\n",
    "            for y, c in pairs_sorted:\n",
    "                key = (y, c)\n",
    "                if key in seen_yc:\n",
    "                    continue\n",
    "                seen_yc.add(key)\n",
    "                seq.append((y, c))\n",
    "\n",
    "            n = len(seq)\n",
    "            if n >= 2:\n",
    "                for i in range(n - 1):\n",
    "                    y_from, c_from = seq[i]\n",
    "                    y_to, c_to = seq[i + 1]\n",
    "                    if c_from == c_to:\n",
    "                        continue\n",
    "                    t = y_to  # transition year\n",
    "\n",
    "                    # leave classification\n",
    "                    returned_to_origin_within_window = False\n",
    "                    for j in range(i + 2, n):\n",
    "                        y_future, c_future = seq[j]\n",
    "                        if y_future > t + x_perm_years:\n",
    "                            break\n",
    "                        if c_future == c_from and y_future >= t + 1:\n",
    "                            returned_to_origin_within_window = True\n",
    "                            break\n",
    "                    if returned_to_origin_within_window:\n",
    "                        left_temp[(t, c_from, c_to)] += 1\n",
    "                    else:\n",
    "                        left_perm[(t, c_from, c_to)] += 1\n",
    "\n",
    "                    # arrival classification\n",
    "                    left_destination_within_window = False\n",
    "                    for j in range(i + 2, n):\n",
    "                        y_future, c_future = seq[j]\n",
    "                        if y_future > t + x_perm_years:\n",
    "                            break\n",
    "                        if c_future != c_to and y_future >= t + 1:\n",
    "                            left_destination_within_window = True\n",
    "                            break\n",
    "                    if left_destination_within_window:\n",
    "                        arr_temp[(t, c_from, c_to)] += 1\n",
    "                    else:\n",
    "                        arr_perm[(t, c_from, c_to)] += 1\n",
    "\n",
    "            parsed_rows += 1\n",
    "\n",
    "        pbar.update(len(chunk))\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # Build output records for Sankey: keep only Israel as source or target\n",
    "    records = []\n",
    "    for key in set(list(left_perm.keys()) + list(left_temp.keys()) +\n",
    "                   list(arr_perm.keys()) + list(arr_temp.keys())):\n",
    "        year, source, target = key\n",
    "        if \"Israel\" not in (source, target):\n",
    "            continue\n",
    "        records.append({\n",
    "            \"year\": year,\n",
    "            \"source\": source,\n",
    "            \"target\": target,\n",
    "            \"left_permanent\": left_perm.get(key, 0),\n",
    "            \"left_temporary\": left_temp.get(key, 0),\n",
    "            \"arrived_permanent\": arr_perm.get(key, 0),\n",
    "            \"arrived_temporary\": arr_temp.get(key, 0),\n",
    "        })\n",
    "\n",
    "    out_df = pd.DataFrame(records).sort_values([\"year\", \"source\", \"target\"]).reset_index(drop=True)\n",
    "    out_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Done. Parsed rows: {parsed_rows}, skipped rows: {skipped_rows}, output rows: {len(records)}\")\n",
    "\n",
    "    return out_df\n",
    "\n",
    "\n",
    "# Usage\n",
    "output_df = compute_sankey_metrics(\n",
    "    input_csv_path=\"../data/moving_between_countries/authors_country_changes_in_israel.csv\",\n",
    "    output_csv_path=\"../data/moving_between_countries/sankey_country_israel.csv\",\n",
    "    x_perm_years=3,\n",
    "    chunksize=50_000\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
